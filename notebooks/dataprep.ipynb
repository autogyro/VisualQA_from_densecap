{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14261\r"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "MAX_LEN = 13\n",
    "\n",
    "def get3DMatrix(captions, embeddings):\n",
    "    res = []\n",
    "    for caption in captions:\n",
    "        sentence = [np.asarray([0]*300,dtype='float32')]*MAX_LEN\n",
    "        words = word_tokenize(caption)\n",
    "        for i, word in enumerate(words):\n",
    "            sentence[i] = embeddings.get(word, np.asarray([0]*300,dtype='float32'))\n",
    "        res.append(sentence)\n",
    "    return np.asarray(res)\n",
    "\n",
    "matrix_map = {}\n",
    "with open('train.csv') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(i, end='\\r')\n",
    "        image_id, captions, questions, answers = line.split('::zz')\n",
    "        captions = captions.split('#:#')\n",
    "        matrix_map[image_id] = get3DMatrix(captions, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14261\r"
     ]
    }
   ],
   "source": [
    "data = {'image_id': [], 'captions': [], 'questions': [], 'answers': [], 'question_ids': [], 'caption_matrix': []}\n",
    "with open('train.csv') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(i, end='\\r')\n",
    "        image_id, captions, questions, answers = line.split('::zz')\n",
    "        captions = captions.split('#:#')\n",
    "        questions = questions.split('#:#')\n",
    "        answers = answers.split('#:#')\n",
    "        question_answers = []\n",
    "        questionsMod = {}\n",
    "        answersMod = {}\n",
    "        for i in range(len(questions)):\n",
    "            if i%2 == 0:\n",
    "                questionsMod[questions[i]] = questions[i+1]\n",
    "        for i in range((len(answers))):\n",
    "            if i %2 == 0:\n",
    "                answersMod[answers[i]] = answers[i+1]\n",
    "        for question_id in questionsMod:\n",
    "            question_answers.append((question_id, questionsMod[question_id], answersMod[question_id]))\n",
    "        for question_id, question, answer in question_answers:\n",
    "            data['image_id'].append(image_id)\n",
    "            data['captions'].append(captions)\n",
    "            data['questions'].append(question)\n",
    "            data['answers'].append(answer)\n",
    "            data['question_ids'].append(question_id)\n",
    "            data['caption_matrix'].append(matrix_map[image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         answers                                     caption_matrix  \\\n",
      "0    living room  [[[0.68758, -0.34531, -0.18579, 0.2387, -0.071...   \n",
      "1            yes  [[[0.68758, -0.34531, -0.18579, 0.2387, -0.071...   \n",
      "2  living room\\n  [[[0.68758, -0.34531, -0.18579, 0.2387, -0.071...   \n",
      "3            yes  [[[0.21497, -0.29447, -0.47612, -0.029865, 0.2...   \n",
      "4              1  [[[0.21497, -0.29447, -0.47612, -0.029865, 0.2...   \n",
      "\n",
      "                                            captions image_id question_ids  \\\n",
      "0  [window with white frame, black leather couch,...    98304     98304001   \n",
      "1  [window with white frame, black leather couch,...    98304     98304000   \n",
      "2  [window with white frame, black leather couch,...    98304     98304002   \n",
      "3  [train on the tracks, train on the tracks, yel...    32773     32773001   \n",
      "4  [train on the tracks, train on the tracks, yel...    32773     32773000   \n",
      "\n",
      "                                questions  \n",
      "0             Where in the house is this?  \n",
      "1     Is the furniture made from leather?  \n",
      "2                     Which room is this?  \n",
      "3  Is there anyone waiting for the train?  \n",
      "4              How many trains are there?  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "print(df.head())\n",
    "df.to_pickle('trainv1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex:1/i:52343\n",
      "ex:2/i:128261\n",
      "ex:3/i:151102\n",
      "ex:4/i:200668\n",
      "ex:5/i:209833\n",
      "ex:6/i:220779\n",
      "ex:7/i:253461\n",
      "ex:8/i:365745\n",
      "ex:9/i:532048\n",
      "ex:10/i:717302\n",
      "ex:11/i:994818\n",
      "ex:12/i:1123331\n",
      "ex:13/i:1148409\n",
      "ex:14/i:1352110\n",
      "ex:15/i:1499727\n",
      "ex:16/i:1533809\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings = {}\n",
    "cnt = 0\n",
    "with open('./../embeddings/glove.840B.300d.txt','r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:],dtype='float32')\n",
    "        except Exception as ex:\n",
    "            cnt += 1\n",
    "            print(\"ex:{}/i:{}\".format(cnt, i))\n",
    "            continue\n",
    "        embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76380"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "mx = 0\n",
    "for index, row in df.iterrows():\n",
    "    captions = row['captions']\n",
    "    for caption in captions:\n",
    "        mx = max(len(caption.split(' ')), mx)\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11, 300)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "MAX_LEN = 11\n",
    "\n",
    "def get3DMatrix(captions, embeddings):\n",
    "    res = []\n",
    "    for caption in captions:\n",
    "        sentence = [np.asarray([0]*300,dtype='float32')]*MAX_LEN\n",
    "        words = word_tokenize(caption)\n",
    "        for i, word in enumerate(words):\n",
    "            sentence[i] = embeddings.get(word, np.asarray([0]*300,dtype='float32'))\n",
    "        res.append(sentence)\n",
    "    return np.asarray(res)\n",
    "        \n",
    "mat = get3DMatrix(captions, embeddings)\n",
    "print(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results_val/results_val.json') as f:\n",
    "    cont = f.read()\n",
    "results = json.loads(cont)\n",
    "with open('results_val/questions.json') as f:\n",
    "    cont = f.read()\n",
    "questions = json.loads(cont)\n",
    "with open('results_val/annotations.json') as f:\n",
    "    cont = f.read()\n",
    "answers = json.loads(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp = {}\n",
    "for result in results['results'][:6750]:\n",
    "    img_id = int(result['img_name'].split('.')[0].split('_')[-1])\n",
    "    mp[img_id] = []\n",
    "    mp[img_id].append(result['captions'][:10])\n",
    "    mp[img_id].append([])\n",
    "    mp[img_id].append([])\n",
    "for question in questions['questions']:\n",
    "    img_id, question, question_id = question['image_id'], question['question'], question['question_id']\n",
    "    if img_id in mp:\n",
    "        mp[img_id][1].append([question_id, question])\n",
    "for answer in answers['annotations']:\n",
    "    img_id, multiple_choice_answer, question_id = answer['image_id'], answer['multiple_choice_answer'], answer['question_id']\n",
    "    if img_id in mp:\n",
    "        mp[img_id][2].append([question_id, multiple_choice_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('val.pkl')\n",
    "mx = 0\n",
    "for index, row in df.iterrows():\n",
    "    captions = row['captions']\n",
    "    for caption in captions:\n",
    "        mx = max(len(caption.split(' ')), mx)\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607560"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "MAX_LEN = 13\n",
    "\n",
    "def get3DMatrix(captions, embeddings):\n",
    "    res = []\n",
    "    for caption in captions:\n",
    "        sentence = [np.asarray([0]*300,dtype='float32')]*MAX_LEN\n",
    "        words = word_tokenize(caption)\n",
    "        for i, word in enumerate(words):\n",
    "            sentence[i] = embeddings.get(word, np.asarray([0]*300,dtype='float32'))\n",
    "        res.append(sentence)\n",
    "    return np.asarray(res)\n",
    "\n",
    "matrix_map = {}\n",
    "for image_id in mp:\n",
    "    captions = mp[image_id][0]\n",
    "    matrix_map[image_id] = get3DMatrix(captions, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'image_id': [], 'captions': [], 'questions': [], 'answers': [], 'question_ids': [], 'caption_matrix': []}\n",
    "for image_id in mp:\n",
    "    captions, questions, answers = mp[image_id]\n",
    "    question_answers = []\n",
    "    questionsMod = {}\n",
    "    answersMod = {}\n",
    "    for q_id, q in questions:\n",
    "        questionsMod[q_id] = q\n",
    "    for q_id, a in answers:\n",
    "        answersMod[q_id] = a\n",
    "    for question_id in questionsMod:\n",
    "        question_answers.append((question_id, questionsMod[question_id], answersMod[question_id]))\n",
    "    for question_id, question, answer in question_answers:\n",
    "        data['image_id'].append(image_id)\n",
    "        data['captions'].append(captions)\n",
    "        data['questions'].append(question)\n",
    "        data['answers'].append(answer)\n",
    "        data['question_ids'].append(question_id)\n",
    "        data['caption_matrix'].append(matrix_map[image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       answers                                     caption_matrix  \\\n",
      "0           no  [[[0.043798, 0.024779, -0.20937, 0.49745, 0.36...   \n",
      "1  city street  [[[0.043798, 0.024779, -0.20937, 0.49745, 0.36...   \n",
      "2          yes  [[[0.043798, 0.024779, -0.20937, 0.49745, 0.36...   \n",
      "3        black  [[[0.043798, 0.024779, -0.20937, 0.49745, 0.36...   \n",
      "4        brush  [[[0.043798, 0.024779, -0.20937, 0.49745, 0.36...   \n",
      "\n",
      "                                            captions  image_id  question_ids  \\\n",
      "0  [a traffic light, a red traffic light, a city ...    360449       3604490   \n",
      "1  [a traffic light, a red traffic light, a city ...    360449       3604491   \n",
      "2  [a traffic light, a red traffic light, a city ...    360449       3604492   \n",
      "3  [a cat in a sink, the cat is looking at the ca...    245764       2457640   \n",
      "4  [a cat in a sink, the cat is looking at the ca...    245764       2457641   \n",
      "\n",
      "                                           questions  \n",
      "0  Is this the best sunset picture you've ever seen?  \n",
      "1                               What street is this?  \n",
      "2           Are there lots of lights in this street?  \n",
      "3  What color is the cat sitting on top of the to...  \n",
      "4                  What is next to the toilet paper?  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=data)\n",
    "print(df.head())\n",
    "df.to_pickle('valv1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_idx = {}\n",
    "with open('./../embeddings/word_idx') as f:\n",
    "    for line in f:\n",
    "        word, idx = line.split(' ')\n",
    "        word_idx[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../embeddings/word_idx_1', 'wb') as f:\n",
    "    pickle.dump(word_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../embeddings/word_idx_1'\n",
    "with open(path,'rb') as file:\n",
    "    word_idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
